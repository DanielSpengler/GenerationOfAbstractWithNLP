from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

tokenizer = AutoTokenizer.from_pretrained("google/roberta2roberta_L-24_cnn_daily_mail")
model = AutoModelForSeq2SeqLM.from_pretrained("google/roberta2roberta_L-24_cnn_daily_mail").cuda()


article = """
'INTRODUCTION DevOps is a software development methodology that intends to automate the process between software development and IT operations. The goal is to reduce the time between committing a change to a system and placing it to production, while ensuring high quality [1]. Compared to traditional software de- velopment process, DevOps provides faster feedback between software development and IT operations so that new features and bug ﬁxes can be released faster to the customers. To ensure the quality and the health of the deployed systems, software logging plays a central role. Software logging in the context of DevOps refers to the practices of developing and maintaining logging code and analyzing the resulting execution logs. Logging code refers to the code snippets that developers inserted into source code (e.g., LOG.info("User " + userName + " logged in")) to monitor the behavior of systems during runtime. There are typically four types of components in a snippet of logging code: a logging object, a verbosity level, static texts, and dynamic contents. In the above example, the logging object is Logger, the verbosity level is info, the static texts are User and logged in, and the dynamic content is userName. Execution logs (a.k.a., logs), which are generated by logging code during runtime, are readily available in large- scale software systems for many purposes like system monitor- ing [2], problem debugging [3], workload characterization [4], and business decision making [5]. Stale or incorrect logging code may cause confusion [6] or even more serious issues like system crash [7]. In particular, there are four major challenges associated with the software logging practices in DevOps: • C1: No existing guidelines on producing high quality logging code. Recent empirical studies show that there are no existing logging guidelines for commercial [8] and open source systems [9], [10]. Developers write logging code solely based on domain expertise and revise them in an ad-hoc fashion [9], [10]. Unlike feature code, which can be examined through testing, it is very challenging to verify the correctness of logging code. • C2: Difﬁculty in maintaining and evolving logging code. As logging code tangles with source code, it is very challenging to maintain and update logging code along with feature code for constantly evolving systems. Al- though there are language extensions (e.g., AspectJ [11]) to support better management of logging code, many industrial and open source systems still choose to inter- mix logging code with feature code [9], [10]. • C3: Limited mechanism for quality feedback. In the context of DevOps, the software testing process is com- pletely changed compared to traditional software devel- opment process, as many testing activities are automated and occur in the ﬁeld [12]. There is limited mechanism for quality feedback from the IT operation to the software development. This problem becomes even more serious, as in DevOps code base evolves more rapidly with usage scenarios being constantly added or modiﬁed. • C4: Heterogeneous and complex telemetry data. Be- sides execution logs, large scale distributed systems also adopt other mechanisms to monitor the health of systems. Some examples are distributed tracing [13] and Applica- tion Performance Monitoring (APM) tools [14]. Existing problem diagnosis techniques only focus on one type of telemetry data (e.g., logs [15] or traces [16]). Very few works try to enrich the analysis by correlating the information among different types of telemetry data. Motivated by the importance and challenges, throughout the thesis, we propose systematic approaches to improving the software logging practices to aid software development and IT operations by leveraging various types of software repositories. Our overall process is shown in Figure 1. For each challenge, we list a corresponding anticipated research outcome. We will further describe them in more details in Section'
"""

input_ids = tokenizer(article, padding=True, truncation=True,max_length=512, add_special_tokens = True, return_tensors="pt").to('cuda:0')
input_ids = input_ids.input_ids

print(input_ids.shape)
print("\n")
#print(input_ids)
output_ids = model.generate(input_ids)[0]
print(output_ids.shape)
print(tokenizer.decode(output_ids, skip_special_tokens=True))